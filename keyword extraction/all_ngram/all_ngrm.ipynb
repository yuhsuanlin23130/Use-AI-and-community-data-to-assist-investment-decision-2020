{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''聯電'''\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pickle    \n",
    "    \n",
    "def preprocess(classorall, df, class_index, n, stopword): \n",
    "    class_TFdict = dict()\n",
    "    class_DFdict = dict()\n",
    "    \n",
    "    for index, row in df.iloc[class_index].iterrows(): \n",
    "        text = str(row[\"title\"]) + str(row[\"content\"])  \n",
    "        text = re.sub(r'[^\\w]','', text)  #remove string not unicode decoded\n",
    "        text = re.sub(r\"[A-Za-z0-9]\", \"\", text) #remove english & number\n",
    "\n",
    "        doc_has_word = []\n",
    "        for t in range(len(text)-(n-1)):\n",
    "            words = text[t:t+n]  \n",
    "            # tf, df\n",
    "            if words not in stopword:\n",
    "                if words in class_TFdict:      #term freq of that class\n",
    "                    class_TFdict[words] += 1\n",
    "                else:\n",
    "                    class_TFdict[words] = 1\n",
    "                if words not in doc_has_word:\n",
    "                    if words in class_DFdict:     #df\n",
    "                        class_DFdict[words] += 1\n",
    "                    else:\n",
    "                        class_DFdict[words] = 1  \n",
    "                    doc_has_word.append(words)\n",
    "                \n",
    "    if classorall == 'class':\n",
    "        key_to_remove = []\n",
    "        for key, val in class_DFdict.items():  #remove the terms whose df <= 10\n",
    "            if val <= 10:\n",
    "                key_to_remove.append(key)\n",
    "        for key in key_to_remove:\n",
    "            del class_DFdict[key]\n",
    "            del class_TFdict[key]\n",
    "        \n",
    "    return class_TFdict, class_DFdict\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('../dataset/utf8/news.csv', encoding=\"UTF-8\")[['post_time','title','content']]\n",
    "df2 = pd.read_csv('../dataset/utf8/forum.csv', encoding=\"UTF-8\")[['post_time','title','content']]\n",
    "df3 = pd.read_csv('../dataset/utf8/bbs.csv', encoding=\"UTF-8\")[['post_time','title','content']]\n",
    "\n",
    "stopword_list = []\n",
    "with open('../dataset/stopwords.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()    \n",
    "        stopword_list.append(data)\n",
    "        \n",
    "risedown =[ ['慘綠','跌','下挫','利空', '看衰','減碼','綠盤','低點','收綠','收黑','重挫','賣超','新低','摜破','賠','虧','黑天鵝','空方','停工','信用破產','悲觀','斷頭','損失'] , ['漲','利多','布局','看好','成長','加碼','上升','上看','紅盤','收紅','買超','攀升','高點','高峰','新高','降息','多方','上車','樂觀', '護盤','台股漲']]\n",
    "\n",
    "df = pd.concat([df1,df2,df3],axis=0)  \n",
    "all_doc_count = df.shape[0]\n",
    "all_doc = list(range(all_doc_count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all  2\n",
      "all  5\n",
      "all  6\n"
     ]
    }
   ],
   "source": [
    "ngrm = [2,3,4,5,6]\n",
    "# 所有文章\n",
    "all_ngram_count = []    \n",
    "all_ngrm = [] \n",
    "for i in ngrm:\n",
    "    print('all ', i)\n",
    "    all_TF, all_DF = preprocess('all', df, all_doc, i, stopword_list) \n",
    "    all_ngram_count.append(len(all_TF))         \n",
    "    # merge (ngram, tf, df)\n",
    "    ngram_tf_df = defaultdict(list)\n",
    "    for k, v in chain(all_TF.items(), all_DF.items()):\n",
    "        ngram_tf_df[k].append(v)   \n",
    "    file = open('all_ngrm[{}].pickle'.format(i), 'wb')\n",
    "    pickle.dump(list(ngram_tf_df.items()), file)\n",
    "    file.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
